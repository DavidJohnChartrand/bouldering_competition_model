{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3666241",
   "metadata": {},
   "outputs": [],
   "source": [
    " browser = Browser('chrome', incognito=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_info(link):\n",
    "\n",
    "    browser.visit(link)\n",
    "    per_info_soupy = soup(browser.html, \"html.parser\")\n",
    "    athlete = per_info_soupy.find_all(\"div\", class_=\"athlete\")\n",
    "    country = athlete[0].find(\"div\", class_=\"country\").find(\"span\").text\n",
    "    name = athlete[0].find(\"h1\", class_=\"name\").text\n",
    "    age = athlete[0].find(\"span\", class_=\"age\").text\n",
    "    hometown = athlete[0].find(\"span\", class_=\"hometown\").text\n",
    "    info = per_info_soupy.find(\"div\", class_=\"personal-info\")\n",
    "    athlete_info = info.find(\"div\",class_=\"text\")\n",
    "    catergories = []\n",
    "    data = []\n",
    "    Athlete_infos = []\n",
    "    try:   \n",
    "        for i in athlete_info:\n",
    "            if i[\"class\"][0]==\"subtitle\":\n",
    "                catergories.append(i.text)\n",
    "            else:\n",
    "                data.append(i.text)\n",
    "\n",
    "        athlete_infos = {catergories[i]: data[i] for i in range(len(catergories))}\n",
    "        Athlete_infos.append(athlete_infos)\n",
    "        \n",
    "    except:\n",
    "        \"NO PERSONAL INFORMATION\"\n",
    "    INFO =[country,name,age, Athlete_infos]\n",
    "    return INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climbers_stats(link):\n",
    "    browser.visit(link)\n",
    "    soupy = soup(browser.html, \"html.parser\")\n",
    "    iframe = soupy.find('iframe')\n",
    "    iframe_url = iframe['data-src']\n",
    "    iframe_url\n",
    "    browser.visit(iframe_url)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_table():\n",
    "    iframesoup = soup(browser.html, \"html.parser\")\n",
    "    table = iframesoup.find('table')\n",
    "    climbers =[]\n",
    "    for row in table.find_all('tr'):\n",
    "        try:\n",
    "            link = row.find_all('td')[1].find(\"a\")[\"href\"]\n",
    "            climber = personal_info(link)\n",
    "            climbers.append(climber)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    return climbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ada0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climbers(url):\n",
    "    climbers_stats(url)\n",
    "    sleep(1)\n",
    "    climbers = loop_table()\n",
    "    return climbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee02ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_climber_df(url):\n",
    "    competitors = climbers(url)\n",
    "    df = pd.DataFrame(competitors)\n",
    "    df = clean_climber_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c8c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_climber_df(df):\n",
    "    personal_info_list = pd.json_normalize(df[3])\n",
    "    personl_info_df = pd.json_normalize(personal_info_list[0])\n",
    "    df[1]=df[1].str.strip()\n",
    "    name_df = df[1].str.split(\" \",expand=True)\n",
    "    for i in range(len(name_df.columns)):\n",
    "        name_df.rename(columns={i:f\"name_{i}\"}, inplace=True)\n",
    "    df[2]=df[2].str.strip(\"Age: \")\n",
    "    df = df.merge(name_df, left_index=True, right_index=True)\n",
    "    df = df.drop([1,3],axis=1)\n",
    "    df = df.merge(personl_info_df,left_index=True, right_index=True)\n",
    "    df = df.rename(columns={0:\"country\",2:\"age\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def women():\n",
    "    women_url = 'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=7'\n",
    "    df = create_climber_df(women_url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def men():\n",
    "    men_url = 'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=3'\n",
    "    df = create_climber_df(men_url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    women_df = women()\n",
    "    men_df = men()\n",
    "    browser.quit()\n",
    "    \n",
    "    women_df.to_csv('women_competitors.csv', index=False)\n",
    "    men_df.to_csv('men_competitors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd14eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afe3948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28304\\2110348309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28304\\2110348309.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;31m#Run scraper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[0mscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28304\\2110348309.py\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mwomen_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwomen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[0mmen_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28304\\2110348309.py\u001b[0m in \u001b[0;36mwomen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwomen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mwomen_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=7'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_climber_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwomen_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28304\\2110348309.py\u001b[0m in \u001b[0;36mcreate_climber_df\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mcompetitors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclimbers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompetitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_climber_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28304\\2110348309.py\u001b[0m in \u001b[0;36mclean_climber_df\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclean_climber_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mpersonal_info_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mpersonl_info_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersonal_info_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "class IFSCBloudererScraper():\n",
    "    \"\"\"\n",
    "    Define a class for the scrapper from the IFSC website\n",
    "    (ifsc-climbing.org)\n",
    "    scrapes both male and female competitors\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize a scraper object with the Chrome Browser instance\n",
    "        Input:\n",
    "            debug - Indicates whther this is a debuf instance\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        \n",
    "        # Create Chrome isntance\n",
    "        self.browser = Browser('chrome', incognito=True)\n",
    "        \n",
    "        sleep(1)\n",
    "    \n",
    "    def personal_info(self, link):\n",
    "        \"\"\"\n",
    "        Returns the information from an individual Athletes page on the \n",
    "        IFSC's website\n",
    "        input:\n",
    "            link - \n",
    "        \"\"\"\n",
    "        \n",
    "        self.browser.visit(link)\n",
    "        per_info_soupy = soup(self.browser.html, \"html.parser\")\n",
    "        athlete = per_info_soupy.find_all(\"div\", class_=\"athlete\")\n",
    "        country = athlete[0].find(\"div\", class_=\"country\").find(\"span\").text\n",
    "        name = athlete[0].find(\"h1\", class_=\"name\").text\n",
    "        age = athlete[0].find(\"span\", class_=\"age\").text\n",
    "        hometown = athlete[0].find(\"span\", class_=\"hometown\").text\n",
    "        info = per_info_soupy.find(\"div\", class_=\"personal-info\")\n",
    "        athlete_info = info.find(\"div\",class_=\"text\")\n",
    "        catergories = []\n",
    "        data = []\n",
    "        Athlete_infos = []\n",
    "        try:   \n",
    "            for i in athlete_info:\n",
    "                if i[\"class\"][0]==\"subtitle\":\n",
    "                    catergories.append(i.text)\n",
    "                else:\n",
    "                    data.append(i.text)\n",
    "\n",
    "            athlete_infos = {catergories[i]: data[i] for i in range(len(catergories))}\n",
    "            Athlete_infos.append(athlete_infos)\n",
    "\n",
    "        except:\n",
    "            \"NO PERSONAL INFORMATION\"\n",
    "        INFO =[country,name,age, Athlete_infos]\n",
    "        return INFO\n",
    "    \n",
    "    def climbers_stats(self, link):\n",
    "        self.browser.visit(link)\n",
    "        soupy = soup(self.browser.html, \"html.parser\")\n",
    "        iframe = soupy.find('iframe')\n",
    "        iframe_url = iframe['data-src']\n",
    "        iframe_url\n",
    "        self.browser.visit(iframe_url)\n",
    "        return\n",
    "    \n",
    "    def loop_table(self):\n",
    "        iframesoup = soup(self.browser.html, \"html.parser\")\n",
    "        table = iframesoup.find('table')\n",
    "        climbers =[]\n",
    "        for row in table.find_all('tr'):\n",
    "            try:\n",
    "                link = row.find_all('td')[1].find(\"a\")[\"href\"]\n",
    "                climber = self.personal_info(link)\n",
    "                climbers.append(climber)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "        return climbers\n",
    "\n",
    "    def climbers(self, url):\n",
    "        self.climbers_stats(url)\n",
    "        sleep(1)\n",
    "        climbers = self.loop_table()\n",
    "        return climbers\n",
    "    \n",
    "    def create_climber_df(self, url):\n",
    "        competitors = self.climbers(url)\n",
    "        df = pd.DataFrame(competitors)\n",
    "        df = self.clean_climber_df(df)\n",
    "        return df\n",
    "    \n",
    "    def clean_climber_df(self, df):\n",
    "        personal_info_list = pd.json_normalize(df[3])\n",
    "        personl_info_df = pd.json_normalize(personal_info_list[0])\n",
    "        df[1]=df[1].str.strip()\n",
    "        name_df = df[1].str.split(\" \",expand=True)\n",
    "        for i in range(len(name_df.columns)):\n",
    "            name_df.rename(columns={i:f\"name_{i}\"}, inplace=True)\n",
    "        df[2]=df[2].str.strip(\"Age: \")\n",
    "        df = df.merge(name_df, left_index=True, right_index=True)\n",
    "        df = df.drop([1,3],axis=1)\n",
    "        df = df.merge(personl_info_df,left_index=True, right_index=True)\n",
    "        df = df.rename(columns={0:\"country\",2:\"age\"})\n",
    "        return df\n",
    "    \n",
    "    def women(self):\n",
    "        women_url = 'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=7'\n",
    "        df = self.create_climber_df(women_url)\n",
    "        return df\n",
    "\n",
    "    def men(self):\n",
    "        men_url = 'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=3'\n",
    "        df = self.create_climber_df(men_url)\n",
    "        return df\n",
    "    \n",
    "    def scrape(self):\n",
    "        women_df = self.women()\n",
    "        men_df = self.men()\n",
    "        self.browser.quit()\n",
    "\n",
    "        women_df.to_csv('women_competitors.csv', index=False)\n",
    "        men_df.to_csv('men_competitors.csv', index=False)\n",
    "        \n",
    "def main():\n",
    "    # Create scraper object\n",
    "    scraper = IFSCBloudererScraper()\n",
    "    \n",
    "    #Run scraper\n",
    "    scraper.scrape()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed142b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
