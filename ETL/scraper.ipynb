{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afe3948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "class IFSCBloudererScraper():\n",
    "    \"\"\"\n",
    "    Define a class for the scrapper from the IFSC website\n",
    "    (ifsc-climbing.org)\n",
    "    scrapes both male and female competitors\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize a scraper object with the Chrome Browser instance\n",
    "        Input:\n",
    "            debug - Indicates whther this is a debuf instance\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        \n",
    "        # Create Chrome isntance\n",
    "        self.browser = Browser('chrome', incognito=True)\n",
    "        \n",
    "        sleep(1)\n",
    "    \n",
    "    def personal_info(self, link):\n",
    "        \"\"\"\n",
    "        Returns the information from an individual Athletes page on the \n",
    "        IFSC's website\n",
    "        input:\n",
    "            link - the url for that specific athlete\n",
    "        return:\n",
    "            INFO - a list of the information from the page\n",
    "        \"\"\"\n",
    "        \n",
    "        self.browser.visit(link)\n",
    "        # grab the html for parsing\n",
    "        per_info_soupy = soup(self.browser.html, \"html.parser\")\n",
    "        \n",
    "        # find the div with class athlete to gather the info from the header\n",
    "        athlete = per_info_soupy.find_all(\"div\", class_=\"athlete\")\n",
    "        country = athlete[0].find(\"div\", class_=\"country\").find(\"span\").text\n",
    "        name = athlete[0].find(\"h1\", class_=\"name\").text\n",
    "        age = athlete[0].find(\"span\", class_=\"age\").text\n",
    "        hometown = athlete[0].find(\"span\", class_=\"hometown\").text\n",
    "        \n",
    "        # Find the personal info div to grab info on the athletes arm span and etc.\n",
    "        info = per_info_soupy.find(\"div\", class_=\"personal-info\")\n",
    "        athlete_info = info.find(\"div\",class_=\"text\")\n",
    "        catergories = []\n",
    "        data = []\n",
    "        Athlete_infos = []\n",
    "        \n",
    "        # Use a exception loop as not all the athletes have the same personal info and some have none\n",
    "        try:   \n",
    "            for i in athlete_info:\n",
    "                if i[\"class\"][0]==\"subtitle\":\n",
    "                    catergories.append(i.text)\n",
    "                else:\n",
    "                    data.append(i.text)\n",
    "\n",
    "            athlete_infos = {catergories[i]: data[i] for i in range(len(catergories))}\n",
    "            Athlete_infos.append(athlete_infos)\n",
    "\n",
    "        except:\n",
    "            \"NO PERSONAL INFORMATION\"\n",
    "        INFO =[country,name,age, Athlete_infos]\n",
    "        return INFO\n",
    "    \n",
    "    def climbers_stats(self, link):\n",
    "        \"\"\"\n",
    "        Enters the iframe allowing us to itterate throught the table\n",
    "        input:\n",
    "            link - the url of the Athletes rankings\n",
    "        \"\"\"\n",
    "        \n",
    "        self.browser.visit(link)\n",
    "        soupy = soup(self.browser.html, \"html.parser\")\n",
    "        iframe = soupy.find('iframe')\n",
    "        iframe_url = iframe['data-src']\n",
    "        iframe_url\n",
    "        self.browser.visit(iframe_url)\n",
    "        return\n",
    "    \n",
    "    def loop_table(self):\n",
    "        \"\"\"\n",
    "        Loops through the table\n",
    "        input:\n",
    "            N/A\n",
    "        return:\n",
    "            climbers - a list of the links \n",
    "        \"\"\"\n",
    "        \n",
    "        iframesoup = soup(self.browser.html, \"html.parser\")\n",
    "        table = iframesoup.find('table')\n",
    "        climbers =[]\n",
    "        for row in table.find_all('tr'):\n",
    "            try:\n",
    "                link = row.find_all('td')[1].find(\"a\")[\"href\"]\n",
    "                climber = self.personal_info(link)\n",
    "                climbers.append(climber)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "        return climbers\n",
    "\n",
    "    def climbers(self, url):\n",
    "        \"\"\"\n",
    "        Combines the previous steps into one function\n",
    "        input:\n",
    "            url - the url of the Athletes rankings\n",
    "        returns:\n",
    "            list of lists of the climbers and their attributes\n",
    "        \"\"\"\n",
    "        \n",
    "        self.climbers_stats(url)\n",
    "        sleep(1)\n",
    "        climbers = self.loop_table()\n",
    "        return climbers\n",
    "    \n",
    "    def create_climber_df(self, url):\n",
    "        \"\"\"\n",
    "        Creates a dataframe from teh climbers functions list\n",
    "        input:\n",
    "            url - the url of the Athletes rankings\n",
    "        returns:\n",
    "            df - a dataframe of the athletes\n",
    "        \"\"\"\n",
    "    \n",
    "        competitors = self.climbers(url)\n",
    "        df = pd.DataFrame(competitors)\n",
    "        df = self.clean_climber_df(df)\n",
    "        return df\n",
    "    \n",
    "    def clean_climber_df(self, df):\n",
    "        \"\"\"\n",
    "        Creates a dataframe from teh climbers functions list\n",
    "        input:\n",
    "            df - the previously created df\n",
    "        returns:\n",
    "            df - cleans the df\n",
    "        \"\"\"\n",
    "        \n",
    "        personal_info_list = pd.json_normalize(df[3])\n",
    "        personl_info_df = pd.json_normalize(personal_info_list[0])\n",
    "        df[1]=df[1].str.strip()\n",
    "        name_df = df[1].str.split(\" \",expand=True)\n",
    "        for i in range(len(name_df.columns)):\n",
    "            name_df.rename(columns={i:f\"name_{i}\"}, inplace=True)\n",
    "        df[2]=df[2].str.strip(\"Age: \")\n",
    "        df = df.merge(name_df, left_index=True, right_index=True)\n",
    "        df = df.drop([1,3],axis=1)\n",
    "        df = df.merge(personl_info_df,left_index=True, right_index=True)\n",
    "        df = df.rename(columns={0:\"country\",2:\"age\"})\n",
    "        return df\n",
    "    \n",
    "    def women(self):\n",
    "        women_url = 'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=7'\n",
    "        df = self.create_climber_df(women_url)\n",
    "        return df\n",
    "\n",
    "    def men(self):\n",
    "        men_url = 'https://www.ifsc-climbing.org/index.php/world-competition/calendar?task=ranking-complete&category=3'\n",
    "        df = self.create_climber_df(men_url)\n",
    "        return df\n",
    "    \n",
    "    def scrape(self):\n",
    "        women_df = self.women()\n",
    "        men_df = self.men()\n",
    "        self.browser.quit()\n",
    "\n",
    "        women_df.to_csv('women_competitors.csv', index=False)\n",
    "        men_df.to_csv('men_competitors.csv', index=False)\n",
    "        \n",
    "def main():\n",
    "    # Create scraper object\n",
    "    scraper = IFSCBloudererScraper()\n",
    "    \n",
    "    #Run scraper\n",
    "    scraper.scrape()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed142b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
